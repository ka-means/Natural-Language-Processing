# Natural-Language-Processing
Natural Language Processing (NLP) course assignments from my Master's in Business Analytics/Data Science at Pontificia Universidad Católica de Chile. Includes hands-on projects covering text preprocessing, vectorization, neural networks, transformers, language models, and intelligent agents.

## Course Structure

### Natural Language Processing
- Text preprocessing techniques
- Basic text analysis

### Vector Representation of Language
- Bag of Words (BoW)
- TF-IDF vectorization
- Word embeddings basics

### Neural Networks and Transformers for NLP
- Deep learning architectures for text
- Introduction to attention mechanisms
- Transformer architecture fundamentals

### Transformers for NLP
- BERT and its variants
- Fine-tuning pre-trained models
- Transfer learning in NLP

### From Architecture to Language Model
- Language model design
- Training objectives
- Model evaluation metrics

###PEFT and Prompting
- Parameter-Efficient Fine-Tuning (PEFT)
- Prompt engineering
- Few-shot and zero-shot learning

### Reasoning and Intelligent Agents
- Chain-of-thought reasoning
- Agent architectures
- Tool use and retrieval

### Large Language Models (LLMs)
- Advanced LLM concepts
- Scaling laws
- Deployment and optimization


## Technologies Used

- Python
- Natural Language Toolkit (NLTK)
- scikit-learn
- TensorFlow / PyTorch
- Hugging Face Transformers
- SpaCy

## Note

These are academic exercises completed as part of my Data Science coursework in the Master's program in Business Analytics at Pontificia Universidad Católica de Chile. This is the first of several assignments that will be uploaded to this repository.

##  Author

Katherin Molina - Master's in Business Analytics (Pontificia Universidad Católica de Chile)

---

*This repository is part of an ongoing series of NLP assignments and will be updated regularly throughout the course.*
